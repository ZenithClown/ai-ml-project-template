{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Boilerplate/Template Design</h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Objective:** The file provides a simple *boilerplate* to concentrate on what is necessary, and stop doing same tasks! The boilerplate is also configured with certain [**nbextensions**](https://gitlab.com/ZenithClown/computer-configurations-and-setups) that I personally use. Install them, if required, else ignore them as they do not participate in any type of code-optimizations. For any new project *edit* this file or `File > Make a Copy` to get started with the project. Some settings and configurations are already provided, as mentioned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T15:50:13.490916Z",
     "start_time": "2023-01-11T15:50:13.479904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Code Version: v0.1.0-beta\n"
     ]
    }
   ],
   "source": [
    "# use the code release version for tracking and code modifications. use the\n",
    "# CHANGELOG.md file to keep track of version features, and/or release notes.\n",
    "# the version file is avaiable at project root directory, check the\n",
    "# global configuration setting for root directory information.\n",
    "# the file is already read and is available as `__version__`\n",
    "__version__ = open(\"../VERSION\", \"rt\").read() # bump codecov\n",
    "print(f\"Current Code Version: {__version__}\") # TODO : author, contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Imports\n",
    "\n",
    "A code must be written such that it is always _production ready_. The conventional guidelines provided under [**PEP8**](https://peps.python.org/pep-0008/#imports) defines the conventional or syntactically useful ways of defining and/or manipulating functions. Necessar guidelines w.r.t. code imports are mentioned below, and basic libraries and import settings are defined.\n",
    "\n",
    " 1. Imports should be on separate lines,\n",
    " 2. Import order should be:\n",
    "    * standard library/modules,\n",
    "    * related third party imports,\n",
    "    * local application/user defined imports\n",
    " 3. Wildcard import (`*`) should be avoided, else specifically tagged with **`# noqa: F403`** as per `flake8` or **`# pylint: disable=unused-import`** as per `pylint`\n",
    " 4. Avoid using relative imports; use explicit imports instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T15:50:34.230463Z",
     "start_time": "2023-01-11T15:50:34.217051Z"
    }
   },
   "outputs": [],
   "source": [
    "import os   # miscellaneous os interfaces\n",
    "import sys  # configuring python runtime environment\n",
    "import time # library for time manipulation, and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T15:51:07.931774Z",
     "start_time": "2023-01-11T15:51:07.926776Z"
    }
   },
   "outputs": [],
   "source": [
    "# use `datetime` to control and preceive the environment\n",
    "# in addition `pandas` also provides date time functionalities\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T15:53:12.042423Z",
     "start_time": "2023-01-11T15:53:12.033096Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy      # dataframe is mutable\n",
    "# from tqdm import tqdm as TQ    # progress bar for loops\n",
    "# from uuid import uuid4 as UUID # unique identifier for objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`logging`**](https://docs.python.org/3/howto/logging.html) is a standard python module that is meant for tracking any events that happen during any software/code operations. This module is super powerful and helpful for code debugging and other purposes. The next section defines a `logging` configuration in **`../logs/`** directory. Modify the **`LOGS_DIR`** variable under *Global Arguments* to change the default directory. The module is configured with a simplistic approach, such that any `print())` statement can be update to `logging.LEVEL_NAME()` and the code will work. Use logging operations like:\n",
    "\n",
    "```python\n",
    " >> logging.debug(\"This is a Debug Message.\")\n",
    " >> logging.info(\"This is a Information Message.\")\n",
    " >> logging.warning(\"This is a Warning Message.\")\n",
    " >> logging.error(\"This is a ERROR Message.\")\n",
    " >> logging.critical(\"This is a CRITICAL Message.\")\n",
    "```\n",
    "\n",
    "Note: some directories related to logging is created by default. This can be updated/changed in the following configuration section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T11:55:57.663629Z",
     "start_time": "2022-05-07T11:55:57.657630Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging # configure logging on `global arguments` section, as file path is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and AI/ML Libraries\n",
    "\n",
    "Import of data analysis and AI/ML libraries required at different intersections. Check settings and configurations [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups) and code snippets [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/tree/master/template/snippets/vscode) for understanding settings that is used in this notebook. The code uses `matplotlib.styles` which is a custom `.mplstyle` file recognised by the `matplotlib` downlodable from [this link](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/tree/master/settings/python/matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T16:17:55.349920Z",
     "start_time": "2023-01-11T16:17:55.336907Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%precision 3\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid');\n",
    "plt.style.use('default-style');\n",
    "\n",
    "pd.set_option('display.max_rows', 50) # max. rows to show\n",
    "pd.set_option('display.max_columns', 15) # max. cols to show\n",
    "np.set_printoptions(precision = 3, threshold = 15) # set np options\n",
    "pd.options.display.float_format = '{:,.2f}'.format # float precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Function(s)\n",
    "\n",
    "It is recommended that any UDFs are defined outside the scope of the *jupyter notebook* such that development/editing of function can be done more practically. As per *programming guidelines* as [`src`](https://fileinfo.com/extension/src) file/directory is beneficial in code development and/or production release. However, *jupyter notebook* requires *kernel restart* if any imported code file is changed in disc, for this frequently changing functions can be defined in this section.\n",
    "\n",
    "**Getting Started** with **`PYTHONPATH`**\n",
    "\n",
    "One must know what are [Environment Variable](https://medium.com/chingu/an-introduction-to-environment-variables-and-how-to-use-them-f602f66d15fa) and how to call/use them in your choice of programming language. Note that an environment variable is *case sensitive* in all operating systems (except windows, since DOS is not case sensitive). Generally, we can access environment variables from terminal/shell/command prompt as:\n",
    "\n",
    "```shell\n",
    "# macOS/*nix\n",
    "echo $VARNAME\n",
    "\n",
    "# windows\n",
    "echo %VARNAME%\n",
    "```\n",
    "\n",
    "Once you've setup your system with [`PYTHONPATH`](https://bic-berkeley.github.io/psych-214-fall-2016/using_pythonpath.html) as per [*python documentation*](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH) is an important directory where any `import` statements looks for based on their order of importance. If a source code/module is not available check necessary environment variables and/or ask the administrator for the source files. For testing purpose, the module boasts the use of `src`, `utils` and `config` directories. However, these directories are available at `ROOT` level, and thus using `sys.path.append()` to add directories while importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append `src` and sub-modules to call additional files these directory are\n",
    "# project specific and not to be added under environment or $PATH variable\n",
    "sys.path.append(os.path.join(\"..\", \"src\")) # parent/source files directory\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"agents\")) # agents for reinforcement modelling\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"engine\")) # derivative engines for model control\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"models\")) # actual models for decision making tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Argument(s)\n",
    "\n",
    "The global arguments are *notebook* specific, however they may also be extended to external libraries and functions on import. The *boilerplate* provides a basic ML directory structure which contains a directory for `data` and a separate directory for `output`. In addition, a separate directory (`data/processed`) is created to save processed dataset such that preprocessing can be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T12:02:30.668471Z",
     "start_time": "2022-05-07T12:02:30.661377Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = \"..\" # the document root is one level up, that contains all code structure\n",
    "DATA = join(ROOT, \"data\") # the directory contains all data files, subdirectory (if any) can also be used/defined\n",
    "\n",
    "# processed data directory can be used, such that preprocessing steps is not\n",
    "# required to run again-and-again each time on kernel restart\n",
    "PROCESSED_DATA = join(DATA, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T12:02:38.898998Z",
     "start_time": "2022-05-07T12:02:38.888970Z"
    }
   },
   "outputs": [],
   "source": [
    "# long projects can be overwhelming, and keeping track of files, outputs and\n",
    "# saved models can be intriguing! to help this out, `today` can be used. for\n",
    "# instance output can be stored at `output/<today>/` etc.\n",
    "# `today` is so configured that it permits windows/*.nix file/directory names\n",
    "today = dt.strftime(dt.strptime(ctime(), \"%a %b %d %H:%M:%S %Y\"), \"%a, %b %d %Y\")\n",
    "print(f\"Code Execution Started on: {today}\") # only date, name of the sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T12:07:25.311475Z",
     "start_time": "2022-05-07T12:07:25.297545Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = join(ROOT, \"output\", today)\n",
    "makedirs(OUTPUT_DIR, exist_ok = True) # create dir if not exist\n",
    "\n",
    "# also create directory for `logs`\n",
    "LOGS_DIR = join(ROOT, \"logs\", open(\"../VERSION\", 'rt').read())\n",
    "makedirs(LOGS_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T12:07:35.345557Z",
     "start_time": "2022-05-07T12:07:35.334528Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename = join(LOGS_DIR, f\"{today}.log\"), # change `reports` file name\n",
    "    filemode = \"a\", # append logs to existing file, if file exists\n",
    "    format = \"%(asctime)s - %(name)s - CLASS:%(levelname)s:%(levelno)s:L#%(lineno)d - %(message)s\",\n",
    "    level = logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input File(s)\n",
    "\n",
    "A typical machine learning project revolves around six important stages (as available in [Amazon ML Life Cycle Documentation](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html)). The notebook boilerplate is provided to address two pillars:\n",
    "\n",
    " 1. **Data Processing:** An integral part of any machine learning project, which is the most time consuming step! A brief introduction and best practices is available [here](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d).\n",
    " 2. **Model Development:** From understanding to deployment, this section address development (training, validating and testing) of an machine learning model.\n",
    "\n",
    "![ML Life Cycle](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/images/ml-lifecycle.png)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
